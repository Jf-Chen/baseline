finetune失败的原因应该是gap的问题，但是直接用local更加失败。

应该试一试空间注意力。

v32试了交叉注意力，没什么效果

v33准备试试non local，主要思想来自Spatial contrastive learning for few-shot classification

### 实验一：

只在meta-train解读加入non local的自注意力





### 实验二：

只在meta-train阶段加入non local的自注意力，并且加入对比损失

结论：大失败，但似乎non local的自注意力有效



计划实验——1月11日，在pretrain阶段加入non local，并且保存，在meta-train阶段一起微调。预训练阶段的non local用自身进行。



### 实验三：

输出support set 在linear下的分布，也就是128x5x5到64的分布，每个样本视为一个[64]的向量，

由于代码不好写，暂时放弃。这个思想来自prompt，下游任务适应上游任务。

### 实验四：

受https://blog.csdn.net/motoight/article/details/119900035 启发

1. 通过约束local descriptor 和 全局特征的语义一致性是否合理？这也在实验中暴露出来了，因为作者无论是在pretrain还是finetune阶段都喜欢加上dense CE loss作为约束，但是我认为图像局部描述符不一定要语义完全一致，如果attention做的足够好应该能够对这些局部语义不一致的地方做抑制。
2. 合理利用图像的局部特征是否对分类任务有益？直觉上来说对图像理解肯定是有益的，但是单单分类任务是否有益？
3. 在对图像做查询的时候应该要考虑对齐，如DeepEMD中通过最优传输对图像局部特征做了matching，得到的相似度自然更好，但是有没有更快捷的方法，比如attention？

试试在pretrain阶段加入attention，抑制局部语义不一致的地方的作用。

选择non-local来抑制不重要的局部特征

