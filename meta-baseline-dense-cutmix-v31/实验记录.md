

#### 做法六

效仿DCAP，将local和avgpool桥接，再计算权重。


```

```

#### 做法七

鉴于DCAP在dense pretrain之后，使用了attentive pooling。我直接替换成fcanet作为pooling。

先用1个epoch试了下，proto+cos+fcanet

```
epoch 1, train 0.2856|0.9637, tval 0.6262|0.7959, val 0.6234|0.7999, 1.5m 1.5m/1.5m (@0)
current_time== 0Y-0M-0D-0H-0Minu
set gpu: 0
dataset: torch.Size([3, 80, 80]) (x12000), 20
num params: 12.5M
test epoch 1: acc=63.99 +- 0.71 (%), loss=0.9026 (@7)
set gpu: 0
dataset: torch.Size([3, 80, 80]) (x12000), 20
num params: 12.5M
test epoch 1: acc=79.78 +- 0.54 (%), loss=0.6180 (@7)
```

2个epoch 结果

```
epoch 1, train 0.2263|0.9732, tval 0.6202|0.7984, val 0.6019|0.8131, 2.8m 2.8m/5.6m (@5)
epoch 2, train 0.1712|0.9798, tval 0.6144|0.7953, val 0.5820|0.8168, 2.8m 5.6m/5.6m (@5)
current_time== 0Y-0M-0D-0H-0Minu
set gpu: 0
dataset: torch.Size([3, 80, 80]) (x12000), 20
num params: 12.5M
  0% 0/200 [00:00<?, ?it/s]layer is used
test epoch 1: acc=64.16 +- 0.71 (%), loss=0.8983 (@7)
set gpu: 0
dataset: torch.Size([3, 80, 80]) (x12000), 20
num params: 12.5M
  0% 0/200 [00:00<?, ?it/s]layer is used
test epoch 1: acc=79.94 +- 0.53 (%), loss=0.6067 (@7)
```

结论： 很难说是finetune的效果还是fcanet的效果。而且fcanet没有经过lr从0.1-》0.001的过程，最好冻结几个阶段。

#### 做法八

重新试试DBRN的做法，只修改query，不修改support.

结果

```
epoch 1, train 0.8820|0.9397, tval 1.0084|0.7143, val 1.0247|0.7362, 1.6m 1.6m/1.6m (@0)
current_time== 0Y-0M-0D-0H-0Minu
set gpu: 0
dataset: torch.Size([3, 80, 80]) (x12000), 20
num params: 12.5M
test epoch 1: acc=61.78 +- 0.74 (%), loss=1.0612 (@7)
set gpu: 0
dataset: torch.Size([3, 80, 80]) (x12000), 20
num params: 12.5M
test epoch 1: acc=71.66 +- 0.61 (%), loss=1.0023 (@7)
```

结论：这种加权方式是否有效值得怀疑。**怀疑DBRN是伪造的结果**。

#### 做法九

鉴于原型是单个向量，在5-shot时不足以反映5个support的分布。改为计算出1+5个相似度，投入一个6->1的linear，用来计算最终的相似度。

这样做有个缺陷，就是5-shot下训练时，有linear是按照5-shot配置的，但1-shot由于尺寸原因无法使用。

#### 做法十

之前得到的linear不要丢，用来算global loss。灵感可以来自ReMP。

DMN4，利用互信息。就是，query基于support的相似度给query加权，support基于query的相似度给support加权。

#### 做法十一

由于加了fcanet的效果不如没加，

不加fcanet, 直接用proto+cos epoch=1，就有 63.99 +- 0.69 | 79.90 +- 0.54

加了fcanet，proto+cos epoch =10 ,有  63.59+-0.75 | 79.00+-0.17

加了fcanet，proto+cos epoch =20 , 只有 62.86 +- 0.23 | 78.07 +- 0.17

考虑到有可能是直接从0.001开始训练fcanet，不适应。可以冻结resnet一段，从0.1开始渐变。再解冻，训练。

#### 做法十二

support内部进行NBNN，挑选出top1x5，query对这5个feature进行加权。

取了shotx5个最近邻的作为support中最重要的，给query加权

结果： 63.56 +- 0.72 | 75.91 +- 0.62 ，虽然1-shot没什么影响，但5-shot降低不少

如果该做法不行，就在权重前面加一个（可学习）超参，超参的目的是防止权重的影响过大。

加了gamma=0.5的超参，结果： 63.36 +- 0.70 | 74.81 +- 0.61

gamma =0.2 结果： 61.86 +- 0.73 | 72.04 +- 0.62

##### 去掉support_inner的对角线

gamma =1 结果： 63.56 +- 0.72  | 75.90 +- 0.62

疑问：为什么1-shot下降不明显，但是5-shot下降明显？

不使用prototype，而是直接用hw个local计算bmm相似度，结果： 55.68 +- 0.74 | 69.90 +- 0.58

gamma = 0.9 ，结果 63.59 +- 0.72 | 75.80 +- 0.62

##### 另一种思路是对support加权，但是query不动







